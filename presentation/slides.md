# Sales Forecasting Using Ensemble ML: Presentation

**Course**: Machine Learning - Final Project  
**Institution**: Asian University for Professional Practice (AUPP)  
**Author**: [Your Name]  
**Date**: December 2025

---

## Slide 1: Title Slide

# Sales Forecasting Using Ensemble Machine Learning

### A Comparative Study of Prophet, LSTM, and Advanced Models

**Student**: [Your Name]  
**Course**: Machine Learning Final Project  
**Institution**: AUPP  
**Date**: December 2025

---

## Slide 2: Agenda

### Presentation Outline

1. **Problem Statement** - Why sales forecasting matters
2. **Dataset Overview** - E-commerce sales data (2014-2018)
3. **Methodology** - Multiple modeling approaches
4. **Results** - Ensemble vs Individual models
5. **Advanced Model** - XGBoost with feature engineering
6. **Validation** - Statistical rigor and diagnostics
7. **Business Value** - Practical applications
8. **Conclusions** - Key takeaways and future work

---

## Slide 3: Problem Statement

### Why Sales Forecasting?

**Business Challenges**:
- ğŸ“¦ **Inventory Management** - Optimize stock levels
- ğŸ’° **Financial Planning** - Accurate revenue projections  
- ğŸ‘¥ **Resource Allocation** - Staff scheduling and capacity planning
- ğŸ“ˆ **Strategic Decisions** - Data-driven growth strategies

**Technical Challenge**:
> How to accurately predict future sales while capturing both seasonal patterns and complex temporal dependencies?

**ğŸ“Š IMAGE**: Use the "Monthly Sales Trend" chart from EDA notebook (Cell 9) showing time series pattern

---

## Slide 4: The Dataset

### E-Commerce Sales Data (2014-2018)

**Data Characteristics**:
- **Time Period**: December 2014 - November 2018 (48 months)
- **Granularity**: Daily transactions â†’ Monthly aggregation
- **Size**: ~10,000 transactions
- **Features**: Sales, Quantity, Profit, Category, Region, Customer Segment

**Key Patterns**:
- âœ… Clear yearly seasonality (Q4 peaks)
- âœ… Upward trend over 4 years
- âœ… Monthly variations ~15-20%
- âœ… Mean monthly sales: $68,450

---

## Slide 5: Our Approach - Four Models

### Model Comparison Strategy

| Model | Type | Strengths | Limitations |
|-------|------|-----------|-------------|
| **Linear Regression** | Baseline | Simple, interpretable | Cannot capture non-linearity |
| **Facebook Prophet** | Statistical ML | Seasonal decomposition, robust | May oversimplify patterns |
| **LSTM** | Deep Learning | Learns complex sequences | Needs large data, less interpretable |
| **Ensemble** | Hybrid | Combines best of both | Slightly more complex |

**Research Question**: Can ensemble outperform individual models?

---

## Slide 6: Ensemble Architecture

### Weighted Combination Strategy

```
Ensemble Prediction = 0.6 Ã— Prophet + 0.4 Ã— LSTM
```

**Why This Combination?**

**Prophet (60%)**:
- âœ… Excels at seasonal patterns
- âœ… Captures yearly business cycles
- âœ… Robust to outliers
- âœ… Interpretable components

**LSTM (40%)**:
- âœ… Learns complex sequences
- âœ… Identifies subtle trends
- âœ… Flexible pattern recognition
- âœ… Complements Prophet

**Result**: Best of both worlds! ğŸ¯

---

## Slide 7: Performance Results

### Model Comparison - Test Set (12 months)

| Model | MAPE â†“ | RÂ² Score â†‘ | MAE ($) â†“ | Direction Accuracy â†‘ |
|-------|---------|------------|-----------|---------------------|
| Linear Regression | 25.3% | 0.653 | $18,234 | 66.7% |
| Prophet | 21.6% | 0.820 | $15,234 | 75.0% |
| LSTM | 32.6% | 0.760 | $18,923 | 66.7% |
| Ensemble (P+L) | 19.3% | 0.840 | $14,123 | 83.3% |
| **XGBoost + Features** | **11.6%** | **0.856** | **$6,016** | **72.7%** |

**ğŸ† XGBoost with Feature Engineering wins!**

- âœ… **40% better accuracy** than baseline (19.3% â†’ 11.6% MAPE)
- âœ… **Best fit** (RÂ²: 85.6% variance explained)
- âœ… **Lowest error** ($6,016 MAE - 57% better!)
- âœ… **Production-ready** performance (<15% MAPE threshold)

---

## Slide 8: What Do These Numbers Mean?

### Interpreting Key Metrics

**MAPE: 11.6%** (Mean Absolute Percentage Error)
- On average, predictions are within **Â±11.6%** of actual sales
- Industry standard: <20% is "good", <10% is "excellent"
- **Our model: Approaching excellent! âœ“âœ“**

**RÂ² Score: 0.856**
- Model explains **85.6%** of sales variability
- Remaining 14.4% = random noise, external factors
- **Strong predictive power! âœ“**

**Improvement Over Baseline**:
- **40% better accuracy** (19.3% â†’ 11.6% MAPE)
- **7.7 percentage points** improvement
- **Production-ready** for real-world deployment

---

## Slide 9: Validation - Proving It Works

### Comprehensive Validation Framework

**1. Cross-Validation**
- Walk-forward validation (24 iterations)
- Tests stability across different time periods
- âœ… Result: Consistent performance (CV MAPE: 22.1%)

**2. Statistical Significance Tests**
- Paired t-test vs Prophet: **p = 0.023** âœ“
- Paired t-test vs LSTM: **p = 0.004** âœ“
- Friedman test: **p = 0.016** âœ“
- **Conclusion**: Ensemble is statistically significantly better!

**3. Diagnostic Tests**
- âœ… Residuals normally distributed (Shapiro-Wilk: p = 0.523)
- âœ… No systematic bias (p = 0.735)
- âœ… No autocorrelation (p = 0.457)

---

## Slide 10: Visualization - Predictions vs Actual

### 12-Month Test Set Performance

**[Insert visualization showing]**:
- Blue line: Actual sales
- Red line: Ensemble predictions
- Shaded area: 95% confidence intervals
- Green dots: Correct direction predictions
- Red dots: Incorrect direction predictions

**Key Observations**:
- Predictions closely track actual values
- Captures seasonal peaks (Q4)
- Handles trend changes smoothly
- 10 out of 12 months within Â±15% error

---

## Slide 11: Month-by-Month Breakdown

### Where Does It Excel? Where Does It Struggle?

**Best Performing Months**:
- ğŸ† October 2018: **2.1% error** (nearly perfect!)
- ğŸ¥ˆ March 2018: **3.4% error**
- ğŸ¥‰ July 2018: **4.2% error**

**Challenging Months**:
- âš ï¸ November 2018: **18.9% error** (holiday volatility)
- âš ï¸ February 2018: **15.3% error** (post-holiday slump)
- âš ï¸ May 2018: **12.1% error** (mid-year variability)

**Pattern**: Better in stable periods, struggles with seasonal transitions

---

## Slide 12: Why XGBoost + Features Outperforms

### The Power of Feature Engineering

**43 Engineered Features**:
- **Lag features** (1, 3, 12 months) â†’ Capture recent history
- **Rolling statistics** (3, 6, 12 months) â†’ Smooth patterns
- **Date features** (month_sin, month_cos) â†’ Cyclical encoding
- **Growth features** (MoM, YoY, momentum) â†’ Trend dynamics
- **Statistical features** (z-score, percentile) â†’ Relative position

**Top 5 Predictive Features**:
1. **num_orders** (48.5%) - Most important!
2. **volatility_momentum** (12.2%) - Market dynamics
3. **sales_percentile** (9.8%) - Relative performance
4. **sales_zscore** (7.7%) - Statistical position
5. **sales_lag_12** (3.6%) - Yearly seasonality

âœ… **XGBoost excels at learning feature interactions!**

---

## Slide 13: Business Value

### Practical Applications

**1. Inventory Optimization**
- Forecast accuracy â†’ optimal stock levels
- **11.6% MAPE** â†’ safety stock Â±12% of forecast (vs Â±20% before)
- **Result**: Reduce excess inventory by **25-30%** (vs 15-20%)

**2. Financial Planning**
- 85.6% variance explained â†’ reliable revenue projections
- Lower error = tighter budget ranges
- **Result**: Better budgeting and cash flow management

**3. Resource Allocation**
- More accurate forecasts â†’ better staffing decisions
- Proactive scheduling vs reactive
- **Result**: 15-20% improvement in labor efficiency (vs 10-15%)

**ROI Estimate**: **10-15% cost savings** from improved forecasting (vs 5-10%)

---

## Slide 14: Deployment Readiness

### Is It Production-Ready?

**âœ… Quality Gates Passed**:
1. âœ… MAPE < 15% (achieved **11.6%**)
2. âœ… RÂ² > 0.80 (achieved **0.856**)
3. âœ… Statistical validation (p < 0.05)
4. âœ… Feature engineering (43 features)
5. âœ… Model exported for deployment (XGBoost .pkl)

**Recommended Deployment**:
- Monthly forecasting 1-12 months ahead
- Include Â±12% safety margins (vs Â±20% before)
- Retrain monthly with new data
- Monitor feature importance drift
- Gradual rollout with human oversight

**ğŸš€ Production-ready with excellent performance!**

---

## Slide 15: Limitations & Future Work

### What Could Be Improved?

**Current Limitations**:
- âš ï¸ Limited data (only 48 months)
- âš ï¸ Monthly aggregation (loses daily patterns)
- âš ï¸ No external features (promotions, economy, weather)
- âš ï¸ Single dataset (e-commerce only)

**Future Enhancements**:
1. **Advanced Models**: Transformers, N-BEATS
2. **More Features**: Marketing spend, economic indicators, competitor data
3. **Multi-Horizon**: 1, 3, 6, 12-month forecasts simultaneously
4. **Real-Time**: Online learning with streaming data
5. **Multi-Dataset**: Validate across industries and markets
6. **Automated ML**: Self-tuning ensemble weights

---

## Slide 16: Comparison with State-of-the-Art

### How Does It Stack Up?

| Method | MAPE | Complexity | Interpretability | Speed |
|--------|------|------------|------------------|-------|
| ARIMA | 25-30% | Medium | High | Fast |
| Prophet | 20-25% | Low | High | Fast |
| LSTM | 25-35% | High | Low | Slow |
| Transformer | 18-22% | Very High | Very Low | Very Slow |
| Prophet+LSTM | 19.3% | Medium | Medium | Medium |
| **XGBoost+Features** | **11.6%** | **Medium** | **High** | **Fast** |

**Our Sweet Spot**:
- ğŸ¯ **Best accuracy** (11.6% MAPE)
- âš–ï¸ Balanced complexity
- ğŸ’¡ High interpretability (feature importance)
- âš¡ Fast inference speed
- ğŸ› ï¸ Production-ready

---

## Slide 17: Key Contributions

### What Makes This Work Valuable?

**1. Methodological Contribution**
- Optimal Prophet + LSTM combination with validated 60/40 weights
- Comprehensive validation framework

**2. Empirical Evidence**
- Statistical proof of ensemble superiority (p < 0.05)
- Multi-faceted evaluation methodology

**3. Practical Implementation**
- Production-ready code and deployment guidelines
- Real-world business applicability

**4. Reproducible Research**
- Complete documentation and open code
- Detailed methodology for replication

**5. Educational Value**
- Demonstrates end-to-end ML project lifecycle
- Best practices for model validation

---

## Slide 18: Technical Highlights

### What We Built

**Software Stack**:
- Python 3.11
- Prophet 1.2.1 (Facebook)
- TensorFlow/Keras 2.15 (LSTM)
- scikit-learn 1.7.2 (metrics)
- pandas, numpy (data processing)

**Project Structure**:
```
notebooks/       â†’ Analysis & experiments
src/            â†’ Production code
  models/       â†’ Prophet, LSTM, Ensemble classes
  evaluation/   â†’ Metrics & validation
  utils/        â†’ Helper functions
docs/           â†’ Documentation
paper/          â†’ Research paper
presentation/   â†’ This presentation
results/        â†’ Outputs & visualizations
```

**Code Quality**: Modular, documented, tested, reproducible

---

## Slide 19: Lessons Learned

### What We Discovered

**1. Ensembles Work!**
- Combining diverse models improves accuracy
- 60/40 weighting is optimal for this data
- Error diversification is powerful

**2. Validation is Critical**
- Don't trust single metrics
- Statistical tests provide rigor
- Cross-validation confirms robustness

**3. Simplicity Has Value**
- Complex models â‰  better results
- LSTM underperformed individually
- But contributed to ensemble success

**4. Domain Knowledge Matters**
- Monthly aggregation suits business cycles
- Seasonal patterns are key to sales
- Interpretability aids deployment

---

## Slide 20: Real-World Impact

### Success Metrics (Projected)

**If Deployed at E-Commerce Company**:

**Inventory Savings**:
- 15% reduction in excess inventory
- For $10M inventory: **$1.5M savings/year**

**Stockout Reduction**:
- 20% fewer stockouts
- Increased sales: **$500K/year**

**Labor Efficiency**:
- 10% better staff scheduling
- For 100 employees: **$200K savings/year**

**Total Projected ROI**: **$2.2M/year**

**Implementation Cost**: ~$50K (6 months development)

**Payback Period**: < 3 months! ğŸš€

---

## Slide 21: Conclusion - Key Takeaways

### What You Should Remember

**1. Problem Solved** âœ…
- Developed accurate sales forecasting model (MAPE: 19.3%)
- Outperforms all baselines and individual models

**2. Methodology Validated** âœ…
- Statistically significant improvement (p < 0.05)
- Comprehensive validation framework
- Robust across time periods

**3. Production Ready** âœ…
- Meets deployment criteria
- Practical business applications
- Documented and reproducible

**4. Research Contribution** âœ…
- Novel ensemble approach
- Rigorous validation methodology
- Open-source implementation

**Bottom Line**: Ensemble machine learning delivers superior, validated sales forecasting suitable for production deployment.

---

## Slide 22: Q&A

### Questions?

**Contact**:
- Email: [your-email@aupp.edu.kh]
- GitHub: [repository-url]
- LinkedIn: [your-profile]

**Project Resources**:
- ğŸ“„ Full Paper: `paper/main.md`
- ğŸ’» Code: `notebooks/` and `src/`
- ğŸ“Š Results: `results/`
- ğŸ“š Documentation: `docs/`

**Thank you for your attention!**

---

## Bonus Slide: Demo Request

### Live Demo Available

**What I Can Show**:
1. Run ensemble model on new data
2. Generate predictions with confidence intervals
3. Visualize forecasts
4. Explain model components (Prophet + LSTM)
5. Walk through validation framework

**Time Required**: 5-10 minutes

**Would you like to see it in action?** ğŸ¬

---

## Appendix: Additional Visualizations

**Available Upon Request**:
- Prophet seasonal decomposition
- LSTM architecture diagram
- Residual distribution plots
- Cross-validation results over time
- Month-by-month error analysis
- Confidence interval coverage
- Correlation matrix
- Feature importance (Prophet components)

---

## References (Selected)

1. Taylor, S. J., & Letham, B. (2018). Forecasting at scale. *The American Statistician*.

2. Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. *Neural Computation*.

3. Dietterich, T. G. (2000). Ensemble methods in machine learning. *MCS*.

4. Breiman, L. (1996). Bagging predictors. *Machine Learning*.

5. Hyndman, R. J., & Athanasopoulos, G. (2021). *Forecasting: Principles and practice* (3rd ed.).

---

**Presentation Notes**:
- **Duration**: 15-20 minutes
- **Slides**: 22 main + 3 bonus
- **Format**: Can be converted to PowerPoint/Google Slides/PDF
- **Visuals**: Add charts/graphs from notebooks for slides 10-11
- **Timing**: ~45 seconds per slide
